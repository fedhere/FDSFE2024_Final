{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedhere/FDSFE2024_Final/blob/main/Instructions_FDSFE_2024_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL EXAM: Foundations of Data Science for Everyone 2024"
      ],
      "metadata": {
        "id": "7o9euxj2Dh7X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptClgVY1Uj0R"
      },
      "source": [
        "**GOAL:** Use Machine Learning methods to predict the presence of heart disease in a patient."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The final will be graded 0-100.\n",
        "\n",
        "- There are 100 available points from 10 tasks described below.\n",
        "\n",
        "-  There are additional optional tasks that can earn you additional points (and compensate for points lots in the required tasks).\n",
        "\n",
        "- Up to 15 additional points can be awarded for a clean and tidy deliver. This includes: properly formatted print statements, control of decimal digits in the answers (should generally be <=2), and a code that can be run from top to bottom without stopping.\n",
        "\n",
        "- In many cases, doing well on the tasks that you do even if you do not finish all the tasks will result in a better grade!\n",
        "\n",
        "\n",
        "- If you are concerned that the exam pressure did not allow you to perform well, at the end of the exam schedule notify me and Willow that you want to schedule a 1-1 interview to explain what you did in the final and what you should have done instead. If possible this request will be accommodated and you will be able to recover some of the points in the exam. Note however that this can go two ways: if you did things right in the exam and you cannot explain them you will lose points and your interview may result in lowering your grade. Only use this option if you feel you underperformed because of exam pressure.\n",
        "\n",
        "\n",
        "The data is a modified version of this dataset https://archive.ics.uci.edu/dataset/45/heart+disease that includes fewer variables and some values have been deliberately modified.\n",
        "\n",
        "The goal is to predict heart desease based on medical and personal data from patients.\n",
        "\n",
        "# TABLE OF CONTENT\n",
        "- TASK 1 Acquire in the data _10 points_\n",
        "  - Get the data from the folder \"data\" inside of the exam repository (2 pts)\n",
        "  - Show the top and the bottom 10 rows of the data. (2 pts)\n",
        "  - Answer the question: why do I ask to show both the top and the bottom of the dataset? (4 pts)\n",
        "  - Report the number of rows and columns in the dataset in a print statement that reads: \"The number of rows in the dataset is: N; the number of columns is M\" with N and M set to the appriopriate number of course. (2 pts)\n",
        "\n",
        "- TASK 2 Read carefully the data dictionary  _5 points_\n",
        "\n",
        "- TASK 3 Check the number of values in the target variable _10 points_\n",
        "  - print the values `target` can take (2 pts)\n",
        "  - Answer the question: Based on the  number of values that the target variable can take, what is the machine learning task we are engaging in if we want to predict target? (4 pts)\n",
        "  - Print the number of instances for each value of `target` (2 pts)\n",
        "  - OPTIONAL: Choose a way to visualize the number of instances in each value in `target`\n",
        "  - Answer the question: why is it important to do check the number of instances of each value? can you give an example of a pair of numbers (instances of one value e.g. =0, instances of the other e.g. =1) that would cause problem when making a prediction?(4 pts)\n",
        "\n",
        "\n",
        "- TASK 4 Address missing values _15 points_\n",
        "  - Answer the question: are there missing values?  (write code to answer the question and explain what in the output of the code shows that there are missing values. There are many ways to do this). (2 pts)\n",
        "  - Visualize missing values (we did this in class in at least two ways) (4 pts)\n",
        "  - Decide what to do with missing values for each column or row (or cell) and \"fix\" the missing values as you see fit (2 pts)\n",
        "  - Describe what you did and JUSTIFY your choice of way to address the problem (4 pts)\n",
        "  - Check that there are no more missing values (1 pts)\n",
        "  - Report on the _percentage_ of data that was loss in the process of handling missing values: how many rows, how many columns, how many entries total. (2 pts)\n",
        "\n",
        "\n",
        "- TASK 5 identify the numerical and categorical variables _6 points_\n",
        "  - save the name of each binary column and print it (2 pts)\n",
        "  - save the name of each categorical column  and print it (2 pts)\n",
        "  - save the names of each numerical column (for example in a list) and print it (2 pts)\n",
        "  \n",
        "\n",
        "- TASK 6 explore the correlation of the features _14 points_\n",
        "  - Visualize the correlation of  features (including the target) and describe your plot in a caption that includes the answers to the following questions:\n",
        "    - which pair of variables are most strongly correlated with each other? (2 pts)\n",
        "    - which is the most strongly correlated variable with the target variable? (2 pts)\n",
        "    - which is the most strongly correlated _numerical_ variable with the target variable? (2 pts)\n",
        "  - plot the distribution of the most correlated variable with target (and describe the plot and the insight that you can derive from it in a caption) (2 pts)\n",
        "  - plot the distribution of the most correlated _numerical_ variable with target (and describe the plot and the insight that you can derive from it in a caption) (2 pts)\n",
        "  - make a pair-plot or scatter-matrix plot of all variables and describe what you see including how the plot is designed, what is the content of each subplot on the _diagonal axis_ and on the _off diagonal axis_ (note, this takes a few minutes) (4 pts)\n",
        "\n",
        "\n",
        "- TASK 7 Model choice _5 points_\n",
        "  - Answer the question: why is logistic regression a reasonable model to use if I want to work in a univariate framework? (3 pts)\n",
        "  - Answer the question: why is random forest a reasonable model to use for the prediction overall? (5 pts)\n",
        "\n",
        "\n",
        "- OPTIONAL TASK Perform a Univariate Logistic regression using the maximally corrleated numerical variable with target as the exhogenous variable\n",
        "  - prepare the dataset for training and testing\n",
        "  - report what is the size of the training and of the testing set. Why did you choose that size split?\n",
        "  - Answer the question: why is it important to evaluate the performance on both a training and a testing set?\n",
        "  - perform the logistic regression\n",
        "  - report the model accuracy (i.e. score) on training and testing datasets\n",
        "  - comment on the accuracy and the risk of overfitting\n",
        "  - use the given code to print out a confusion matrix for your model. Write a caption for it  \n",
        "\n",
        "- TASK 8 model target using a random forest model _15 points_\n",
        "  - generate the feature set `X` to include all variables in the problem and `y` to `target` (1 pts)\n",
        "  - set the model with the following hyperparameters: `n_estimators=100, max_depth=15, random_state=302` (1 pts)\n",
        "  - prepare the dataset for training and testing (2 pts)\n",
        "  - Answer the question (if you did not in the previous task): why is it important to evaluate the performance on both a training and a testing set? (5 pts)\n",
        "  - Answer the question: why is scaling or standardizing the data not necessary with this model (note, it was also not necessary with the logistic regression model, but for different reasons!) (5 pts)\n",
        "  - run a random forest model (1 pts)\n",
        "\n",
        "- TASK 9 model evaluation _10 points_\n",
        "  - report the model accuracy (i.e. score) on training and testing datasets (1 pts)\n",
        "  - comment on the accuracy and overfitting (5 pts)\n",
        "  - use the given code to print out a confusion matrix for your model. Write a caption for it (4 pts)\n",
        "\n",
        "- TASK 10 fix overfitting _10 points_\n",
        "\n",
        "  - What can you do about overfitting? control the appropriate hyperparameter(s) and redo the model with those values, report the training and testing score (what do they say about overfitting?) and redo the confusion matrix (5 pts)\n",
        "  - Answer the question: Is the model better? describe how and why (or why not) (5 pts)\n",
        "\n",
        "\n",
        "- OPTIOINAL EXTRA CREDIT : feature importance\n",
        "\n"
      ],
      "metadata": {
        "id": "moUSVvz2bdh7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "tb6dH0ZvUj0S"
      },
      "outputs": [],
      "source": [
        "#system imports\n",
        "import sys\n",
        "\n",
        "#useful package for data handling\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "#plotting packages\n",
        "import matplotlib # collection of functions for scientific and publication-ready visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#missing variables\n",
        "import missingno as msno\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "#model preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#modeling packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#for model evaluation\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwqOx8kwUj0S"
      },
      "source": [
        "# TASK 1 Acquire in the data _10 points_\n",
        "- Get the data from the folder \"data\" inside of the exam repository\n",
        "- Show the top and the bottom 10 rows of the data.\n",
        "- Answer the question: why do I ask to show both the top and the bottom of the dataset?\n",
        "- Report the number of rows and columns in the dataset in a print statement that reads: \"The number of rows in the dataset is: N; the number of columns is M\" with N and M set to the appriopriate number of course.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJwwzDhCUj0T"
      },
      "outputs": [],
      "source": [
        "heart = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1HQFW6AUj0T"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "AQLCsLn_Uj0U",
        "outputId": "b4f5ed23-5282-4fad-ed98-6580367c7b6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  gender   cp  trtbps   chol  fbs  restecg  thalachh  exng  oldpeak  \\\n",
              "293   67     1.0  2.0     152  212.0  0.0      0.0       150   0.0      0.8   \n",
              "294   44     1.0  0.0     120  169.0  0.0      1.0       144   1.0      NaN   \n",
              "295   63     1.0  0.0     140  187.0  NaN      0.0       144   1.0      4.0   \n",
              "296   63     0.0  0.0     124  197.0  NaN      1.0       136   1.0      0.0   \n",
              "297   59     1.0  0.0     164  176.0  1.0      0.0        90   0.0      1.0   \n",
              "298   57     0.0  0.0     140  241.0  0.0      1.0       123   1.0      0.2   \n",
              "299   45     1.0  3.0     110  264.0  0.0      1.0       132   0.0      1.2   \n",
              "300   68     1.0  0.0     144  193.0  1.0      1.0       141   0.0      3.4   \n",
              "301   57     1.0  0.0     130  131.0  0.0      1.0       115   1.0      NaN   \n",
              "302   57     0.0  NaN     130  236.0  0.0      0.0       174   0.0      0.0   \n",
              "\n",
              "     slp  caa  thall  target  \n",
              "293  1.0    0      3       0  \n",
              "294  0.0    0      1       0  \n",
              "295  2.0    2      3       0  \n",
              "296  1.0    0      2       0  \n",
              "297  1.0    2      1       0  \n",
              "298  1.0    0      3       0  \n",
              "299  1.0    0      3       0  \n",
              "300  1.0    2      3       0  \n",
              "301  1.0    1      3       0  \n",
              "302  1.0    1      2       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fd11090-1403-4dbd-b317-17ec64e69ca8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>67</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>152</td>\n",
              "      <td>212.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>144</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>63</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>140</td>\n",
              "      <td>187.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>63</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>124</td>\n",
              "      <td>197.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>136</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>59</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>164</td>\n",
              "      <td>176.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>140</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>123</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>45</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>110</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>68</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fd11090-1403-4dbd-b317-17ec64e69ca8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fd11090-1403-4dbd-b317-17ec64e69ca8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fd11090-1403-4dbd-b317-17ec64e69ca8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1d2c8214-fa6a-4f57-a1f6-4c0d35fb5a5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d2c8214-fa6a-4f57-a1f6-4c0d35fb5a5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1d2c8214-fa6a-4f57-a1f6-4c0d35fb5a5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"heart\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 44,\n        \"max\": 68,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          67,\n          44,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.48304589153964794,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1303883305208782,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trtbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 110,\n        \"max\": 164,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          120,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39.07030699762787,\n        \"min\": 131.0,\n        \"max\": 264.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          131.0,\n          169.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4629100498862757,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5163977794943223,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalachh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 90,\n        \"max\": 174,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          115,\n          144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exng\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5270462766947299,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5415669208401468,\n        \"min\": 0.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4714045207910317,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# check below: the bottom of the file should look like this if you read it in correctly\n",
        "... #your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do I ask to show both the top and the bottom of the dataset?  \n",
        "\n",
        "_YOUR ANSWER HERE_\n"
      ],
      "metadata": {
        "id": "2RDqoup04yyV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLXDLb-sUj0T",
        "outputId": "46e97ac6-eb0c-4a58-beb2-06be46a9cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of rows in the dataset is: 303; the number of columns is 14\n"
          ]
        }
      ],
      "source": [
        "print(\"..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyg5AUktUj0U"
      },
      "source": [
        "# TASK 2 Read carefully the data dictionary that follows; it will help you in the analysis! _5 points_\n",
        "\n",
        "Columns name description and units (from UCI data website):\n",
        "- `cp`: chest pain type\n",
        "      Value 0: typical angina (most serious)\n",
        "      Value 1: atypical angina\n",
        "      Value 2: non-anginal pain\n",
        "      Value 3: asymptomatic (least serious)\n",
        "- `trestbps`: resting blood pressure (in mm Hg on admission to the hospital)\n",
        "- `chol`: serum cholestoral in mg/dl\n",
        "- `fbs`: fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
        "\n",
        "      A fasting blood sugar level less than 100 mg/dL is normal. From 100 to 120 mg is considered prediabetes. If it is 125 mg/dL or higher on two separate tests, you have diabetes.\n",
        "- `restecg`: resting electrocardiographic results\n",
        "- `thalach`: maximum heart rate achieved [beats per minute]\n",
        "- `exang`: exercise induced angina (1 = yes; 0 = no)\n",
        "- `oldpeak`: ST depression induced by exercise relative to rest.\n",
        "      ST depression is a finding on an electrocardiogram (EKG) that indicates an underlying heart condition.\n",
        "- `slope`: the slope of the peak exercise ST segment\n",
        "- `ca`: number of major vessels (0-3) colored by flouroscopy\n",
        "- `thal`: 3 = normal; 6 = fixed defect; 7 = reversable defect.\n",
        "\n",
        "      This refers to Thalassemia, an inherited blood disorder that causes your body to have less hemoglobin than normal\n",
        "\n",
        "\n",
        "- `target`: refers to the presence of heart disease in the patient (1=yes, 0=no)\n",
        "      Value 0: < 50% diameter narrowing\n",
        "      Value 1: > 50% diameter narrowing\n",
        "\n",
        "WRITE YOUR NAME HERE  BELOW THIS LINE IN THIS CELL TO DEMONSTRATE YOU READ THIS LIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz5B9cu4Uj0V"
      },
      "source": [
        "# TASK 3 Check the number of values in the target variable _10 points_\n",
        "- print how many values `target` can take\n",
        "- Answer the question: Based on the  number of values that the target variable can take, what is the machine learning task we are engaging in if we want to predict target?\n",
        "- Print the number of instances for each value of `target`.\n",
        "- OPTIONAL: Choose a way to visualize the number of instances in each value in `target`\n",
        "- Answer the question: why is it important to do check the number of instances of each value? can you give an example of a pair of numbers (instances of one value, instances of the other, e.g. =0, instances of the other e.g. =1) that would cause problem when making a prediction?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgeurDGvUj0V"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the number of values that the target variable can take, what is the machine learning task we are engaging in if we want to predict target?\n",
        "\n",
        "_YOUR ANSWER HERE_\n"
      ],
      "metadata": {
        "id": "LUKcvOoF5Pzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u2CMm2oUj0V"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t02IdclUj0V"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "why is it important to do check the number of instances of each value? can you give an example of a pair of numbers (instances of one value, instances of the other, e.g. =0, instances of the other e.g. =1) that would cause problem when making a prediction?\n",
        "\n",
        "_YOUR ANSWER HERE_\n"
      ],
      "metadata": {
        "id": "uv3KmGMx5YwN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk2EaCTGUj0V"
      },
      "source": [
        "# TASK 4 Address missing values _12 points_\n",
        "- Are there missing values?  (write code to answer the question and explain what in the output of the code shows that there are missing values. There are many ways to do this).\n",
        "- Visualize missing values (we did this in class in at least two ways) and remember that when you make a plot you also need to have a caption that describes how the plot is designed and what insight you derive from it for it to ount!\n",
        "- Decide what to do with missing values for each column or row (or cell)\n",
        "- Describe what you did and JUSTIFY your choice of way to address the problem\n",
        "- Check that there are no more missing values\n",
        "- Report on the _percentage_ of data that was loss in the process of handling missing values: how many rows, how many columns, how many entries total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEN4JPv6Uj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE3KFoDzUj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycWmRxxfUj0W"
      },
      "outputs": [],
      "source": [
        "# Missing data visualization and caption\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iocEwv3uUj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28P5eYbaUj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3QKSe09Uj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describe what you did and JUSTIFY your choice of way to address the problem\n",
        "\n",
        "_ YOUR ANSWER HERE_"
      ],
      "metadata": {
        "id": "czSQdAnmUj0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJSiPyRWUj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVX70djFUj0W",
        "outputId": "77f2fcd7-77bc-45e2-d723-868d2c7f84e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of data lost: X% observations, Y% variables\n",
            "Amount of data lost: Z% entries\n"
          ]
        }
      ],
      "source": [
        "print(\"Amount of data lost: {0}% observations, {1}% variables\".format(\"X\", \"Y\"))\n",
        "print(\"Amount of data lost: {0}% entries\".format(\"Z\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGESLTyqUj0W"
      },
      "source": [
        "# TASK 5 identify the numerical and categorical variables _6 points_\n",
        "- save the names of each numerical column (for example in a list) and print it\n",
        "- save the name of each binary column and print it\n",
        "- save the name of each categorical column  and print it\n",
        "\n",
        "(hint: since there are missing values, some columns will be read as float64 just because they include NaNs even if the are really intergers. You can check what variables have exactly 2 values, and what variables have <10 values, and assume that this is a good indicator of the categorical nature of a column/feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esqe92l_Uj0X"
      },
      "outputs": [],
      "source": [
        "qualitative = []\n",
        "quantitative = []\n",
        "binary = []\n",
        "...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlIuZrcvUj0W"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_hOtLhqUj0X"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "FXaXcOWF6-9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5N-yswmUj0X"
      },
      "source": [
        "# TASK 6 explore the correlation of the features _14 points_\n",
        "- Visualize the correlation of  features (including the target)\n",
        "- Describe your plot in a caption that includes the answers to the following questions:\n",
        "  - which pair of variables are most strongly correlated with each other?\n",
        "  - which is the most strongly correlated variable with the target variable?\n",
        "  - which is the most strongly correlated _numerical_ variable with the target variable?\n",
        "  - which is the least strongly correlated variable with the target variable? (you will use this later so take care this task is done well!)\n",
        "- plot the distribution of the most correlated variable with target (and describe the plot and the insight that you can derive from it in a caption)\n",
        "- plot the distribution of the most correlated _numerical_ variable with target (and describe the plot and the insight that you can derive from it in a caption)\n",
        "- make a pair-plot or scatter-matrix plot of all variables and describe what you see including how the plot is designed, what is the content of each subplot on the _diagonal axis_ and on the _off diagonal axis_ (note, this takes a few minutes)\n",
        "\n",
        "(hint: think carefully about this: you want to find out which variables may be  good predictors of the target. if the variable is linearly correlated, which is what you are probing here, i.e. if plotting the variable against the target results in a line, _regardless of the specific slope of that line_, that would be a good predictor!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW5A9PXRUj0X"
      },
      "outputs": [],
      "source": [
        "X = ...\n",
        "Y = ...\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHZtlXIMUj0X"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKI08agdUj0X"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv9D3FicUj0c"
      },
      "outputs": [],
      "source": [
        "print(\"maximum correlation overall: {} and {}\".format(\"...\", \"...\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p63lJL-Uj0c"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgQZZEA5Uj0c"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abWTkT3SUj0c"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF4BhmtBUj0c"
      },
      "outputs": [],
      "source": [
        "print(f\"Maximum correlation of targets is ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzaW94OpUj0d"
      },
      "outputs": [],
      "source": [
        "print(f\"Maximum correlation of targets with numerical variables is ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czH_pfajUj0d",
        "outputId": "f84fe235-1d46-4078-c6b8-22343ae74e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max correlation with target exng;  max correlation for numerical variables with target thalachh\n"
          ]
        }
      ],
      "source": [
        "print(\"max correlation with target {0:};  max correlation for numerical variables with target {1:}\".format(maxcorr, maxcorrnum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhf_0a2sUj0d"
      },
      "outputs": [],
      "source": [
        "# plot the distribution of the most correlated  variable in a plot and comment in a caption\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylkmw0SiUj0d"
      },
      "outputs": [],
      "source": [
        "# plot the distribution of the most correlated numerical variable in a plot and comment in a caption\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw9rVdmyUj0d"
      },
      "outputs": [],
      "source": [
        "# pair plot or scatter matrix plot and caption\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHgkgtFWUj0d"
      },
      "source": [
        "\n",
        "# TASK 7 Model choice _5 points_\n",
        "\n",
        "You will make two models:\n",
        "- a univariate logistic regression using the single most correlated numerical variable to predict target\n",
        "- a random forest using all variables to predict target\n",
        "\n",
        "For you to do:\n",
        "- Answer the question: why is logistic regression a reasonable model to use if I want to work in a univariate framework?\n",
        "- Answer the question: why is random forest a reasonable model to use for the prediction overall?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is logistic regression a reasonable model to use if I want to work in a univariate framework?\n",
        "\n",
        "\n",
        "_YOUR ANSWERS HERE_"
      ],
      "metadata": {
        "id": "tiFclEmw3P2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is random forest a reasonable model to use for the prediction overall?\n",
        "\n",
        "\n",
        "_YOUR ANSWERS HERE_\n"
      ],
      "metadata": {
        "id": "ioMQNtrG7hON"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB2pROzSUj0d"
      },
      "source": [
        "# OPTIONAL TASK Perform a Univariate Logistic regression using the maximally corrleated numerical variable with target as the exhogenous variable\n",
        "apprioriately split the data into training and testing\n",
        "- set `X` to the numerical column with the highest correlation with target, as identified in the previous step. Set y to the target column.\n",
        "- prepare the dataset for training and testing\n",
        "- report what is the size of the training and of the testing set. Why did you choose that size split?\n",
        "- Answer the question: why is it important to evaluate the performance on both a training and a testing set?\n",
        "- perform the logistic regression\n",
        "- report the model accuracy (i.e. score) on training and testing datasets.\n",
        "- comment on the accuracy and the risk of overfitting\n",
        "- use the given code to print out a confusion matrix for your model. Write a caption for it (note: the code assumes the following:\n",
        "    - the test target variable is called `y_test`\n",
        "    - the model predictions on the test data are stored in the variable `Y_pred`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98SUD0GoUj0d"
      },
      "outputs": [],
      "source": [
        "X = ...\n",
        "y = ...\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqIZyFTpUj0d"
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuLFxGUUj0d",
        "outputId": "c0762364-da53-4dd3-80bf-3d7c0546fdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score: ...\n",
            "Testing Score: ...\n"
          ]
        }
      ],
      "source": [
        "model = ...\n",
        "print(\"Training Score: ...\")\n",
        "print(\"Testing Score: ...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is it important to evaluate the performance on both a training and a testing set?\n",
        "\n",
        "_YOUR ANSWER HERE_"
      ],
      "metadata": {
        "id": "Y56r-ErS73Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on the accuracy and the risk of overfitting (please **don't** say \"accuracy is good\" or \"accuracy is bad\". Rather explain what the score value you printed above actually means in terms of predictions)\n",
        "\n",
        "_YOUR ANSWER HERE_\n"
      ],
      "metadata": {
        "id": "5gI-oNuK7-XY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8beKooUMUj0e"
      },
      "outputs": [],
      "source": [
        "# CONFUSION MATRIX CODE\n",
        "\n",
        "LR_confusion_matrix = confusion_matrix(y_test,Y_pred)\n",
        "class_names = [\"no disease\", \"heart disease\"]\n",
        "fig,ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "\n",
        "sns.heatmap(pd.DataFrame(LR_confusion_matrix)\n",
        "            , annot = True, cmap = 'Greens', fmt = 'g')\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.xticks(tick_marks + 0.5, class_names)\n",
        "plt.yticks(tick_marks + 0.5, class_names)\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix for logistic regression')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmP5sC9KUj0e"
      },
      "source": [
        "# TASK 8 model target using a random forest model _15 points_\n",
        "  - generate the feature set `X` to include all variables in the problem and `y` to `target`\n",
        "  - set the model with the following hyperparameters: `n_estimators=100, max_depth=15, random_state=302`\n",
        "  - prepare the dataset for training and testing\n",
        "  - Answer the question (if you did not in the previous task): why is it important to evaluate the performance on both a training and a testing set?\n",
        "  - Answer the question: why is scaling or standardizing the data not necessary with this model (note, it was also not necessary with the logistic regression model, but for different reasons!)\n",
        "  - run a random forest model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdsMkSJwUj0e"
      },
      "outputs": [],
      "source": [
        "X = ...\n",
        "y = ...\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "1C2ocs4p8Yrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ...\n",
        "\n"
      ],
      "metadata": {
        "id": "1XNklHcO8ZPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the question (if you did not in the previous task): Why is it important to evaluate the performance on both a training and a testing set?\n",
        "\n",
        "_YOUR ANSWER HERE_\n",
        "  "
      ],
      "metadata": {
        "id": "1ZUovyZJ8wpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is scaling or standardizing the data not necessary with this model (note, it was also not necessary with the logistic regression model, but for different reasons!)\n",
        "\n",
        "_YOUR ANSWER HERE_"
      ],
      "metadata": {
        "id": "MrBdBpiP8wdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 9 model evaluation _10 points_\n",
        "  - report the model accuracy (i.e. score) on training and testing datasets\n",
        "  - comment on the accuracy and overfitting\n",
        "  - use the given code to print out a confusion matrix for your model. Write a caption for it"
      ],
      "metadata": {
        "id": "0bvp6JBwhf-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfRGScK0Uj0e",
        "outputId": "aa611303-c0ee-4577-b370-799429ff7c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score: ...\n",
            "Testing Score: ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "...\n",
        "print(\"Training Score: ...\")\n",
        "print(\"Testing Score: ...\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on the accuracy and the risk of overfitting (please **don't** say \"accuracy is good\" or \"accuracy is bad\". Rather explain what the score value you printed above actually means in terms of predictions)\n",
        "\n",
        "_YOUR ANSWER HERE_\n"
      ],
      "metadata": {
        "id": "LKTgjaBZ8cNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbynxb29Uj0e"
      },
      "outputs": [],
      "source": [
        "# CONFUSION MATRIX CODE\n",
        "RF_confusion_matrix = confusion_matrix(y_test,Y_pred)\n",
        "class_names = [\"no disease\", \"heart disease\"]\n",
        "fig,ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "\n",
        "sns.heatmap(pd.DataFrame(RF_confusion_matrix), annot = True, cmap = 'Greens', fmt = 'g')\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.xticks(tick_marks + 0.5, class_names)\n",
        "plt.yticks(tick_marks + 0.5, class_names)\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix for logistic regression')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc4H-uWiUj0e"
      },
      "source": [
        "# TASK 10 fix overfitting _10 points_\n",
        "What can you do about overfitting? control the appropriate hyperparameter(s) and redo the model with those values\n",
        "\n",
        "Answer the question: Is the model better? describe how and why (or why not)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EQssTlUUj0e",
        "outputId": "bd8804c4-6333-4539-d0da-c874cd3f1c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score: ...\n",
            "Testing Score: ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = ...\n",
        "print(\"Training Score: ...\")\n",
        "print(\"Testing Score: ...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlZo4NK7Uj0e"
      },
      "outputs": [],
      "source": [
        "# CONFUSION MATRIX CODE\n",
        "RF_confusion_matrix = confusion_matrix(y_test,Y_pred)\n",
        "class_names = [\"no disease\", \"heart disease\"]\n",
        "fig,ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "\n",
        "sns.heatmap(pd.DataFrame(RF_confusion_matrix), annot = True, cmap = 'Greens', fmt = 'g')\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.xticks(tick_marks + 0.5, class_names)\n",
        "plt.yticks(tick_marks + 0.5, class_names)\n",
        "ax.xaxis.set_label_position('top')\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix for random forest controlling overfit regression')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the model better? describe how and why (or why not)\n",
        "\n",
        "_YOUR CODE HERE_"
      ],
      "metadata": {
        "id": "JxisjU909PTu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Akd7nzUj0e"
      },
      "source": [
        "# EXTRA CREDIT\n",
        "\n",
        "- perform feature importance analysis and intepret it in the light of the correlation analysis\n",
        "- what can you conclulde about the feature importance keeping into account the correlation analysis you did before?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PqInYYkZdHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE6bb5eVUj0e"
      },
      "source": [
        "Thanks [towards data science](https://towardsdatascience.com/a-summary-of-the-basic-machine-learning-models-e0a65627ecbe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}